# streamlit_app.py
import base64
import json
import re
import requests
import streamlit as st
from typing import List, Dict, Optional, Tuple
from notion_client import Client as Notion
from mistralai import Mistral
import unicodedata
from io import BytesIO
from PIL import Image, ImageOps, ImageFilter, ImageEnhance

# ===================
# CONFIG
# ===================
st.set_page_config(page_title="Scan carte → Notion (Mistral)", page_icon="🪪", layout="centered")

NOTION_TOKEN = st.secrets["NOTION_TOKEN"]
NOTION_DB    = st.secrets["NOTION_DB"]            # database_id
MISTRAL_KEY  = st.secrets["MISTRAL_API_KEY"]

# OCR (REST)
MISTRAL_OCR_URL   = st.secrets.get("MISTRAL_OCR_URL", "https://api.mistral.ai/v1/ocr")
MISTRAL_OCR_MODEL = st.secrets.get("MISTRAL_OCR_MODEL", "mistral-ocr-latest")

# Chat (SDK)
MISTRAL_CHAT_MODEL = st.secrets.get("MISTRAL_CHAT_MODEL", "mistral-large-latest")

# Agents (websearch)
MISTRAL_AGENTS_URL  = st.secrets.get("MISTRAL_AGENTS_URL", "https://api.mistral.ai/v1")
MISTRAL_AGENT_MODEL = st.secrets.get("MISTRAL_AGENT_MODEL", MISTRAL_CHAT_MODEL)

# ----- PROPRIÉTÉS NOTION (hors title qui est détecté dynamiquement)
PROP_STATUS       = "Statut"                                        # status OU select
PROP_COMPANY      = "Entreprise"                                    # rich_text
PROP_EMAIL        = "E-mail"                                        # email
PROP_PHONE        = "Téléphone"                                     # phone_number
PROP_TOPIC        = "De quoi désirez-vous discuter ?"               # multi_select
PROP_NOTES        = "Parlez nous de vos besoins en quelques mots"   # rich_text
PROP_EMAIL_DRAFT  = "Brouillon à envoyer"                           # rich_text

TARGET_STATUS_VALUE = "Leads entrant"
TOPIC_OPTIONS = ["Formation", "Module", "Audit IA"]

DEBUG = False  # passe à True si tu veux voir les logs de titre

# Clients
notion  = Notion(auth=NOTION_TOKEN)
mistral = Mistral(api_key=MISTRAL_KEY)

# ===================
# OCR
# ===================
def preprocess_for_ocr(img_bytes: bytes) -> bytes:
    img = Image.open(BytesIO(img_bytes))
    img = ImageOps.exif_transpose(img)
    img = img.convert("L")
    img = ImageEnhance.Contrast(img).enhance(1.6)
    img = img.filter(ImageFilter.UnsharpMask(radius=1.0, percent=160, threshold=3))
    shortest = min(img.size)
    if shortest < 1000:
        scale = 1000 / shortest
        img = img.resize((int(img.width * scale), int(img.height * scale)), Image.LANCZOS)
    out = BytesIO()
    img.save(out, format="JPEG", quality=92, optimize=True)
    return out.getvalue()

def _guess_data_url(image_bytes: bytes, fallback="image/jpeg") -> str:
    header = image_bytes[:8]
    if header.startswith(b"\x89PNG\r\n\x1a\n"):
        mime = "image/png"
    elif header[:3] == b"\xff\xd8\xff":
        mime = "image/jpeg"
    else:
        mime = fallback
    b64 = base64.b64encode(image_bytes).decode()
    return f"data:{mime};base64,{b64}"

def call_mistral_ocr(image_bytes: bytes) -> str:
    data_url = _guess_data_url(image_bytes)
    payload = {
        "model": MISTRAL_OCR_MODEL,
        "document": {"type": "image_url", "image_url": data_url},
    }
    r = requests.post(
        MISTRAL_OCR_URL,
        headers={"Authorization": f"Bearer {MISTRAL_KEY}", "Content-Type": "application/json"},
        json=payload,
        timeout=60,
    )
    r.raise_for_status()
    resp = r.json()
    pages = resp.get("pages", [])
    text = "\n\n".join(p.get("markdown", "") for p in pages).strip()
    return text or resp.get("text", "")

# ===================
# UTIL – nettoyage / heuristiques
# ===================
_md_link = re.compile(r'!\[.*?\]\(.*?\)|\[(.*?)\]\(.*?\)')
_md_head = re.compile(r'^\s{0,3}#{1,6}\s*')
_md_emph = re.compile(r'(\*\*|\*|__|_)')
_md_code = re.compile(r'`+')
_md_bullet = re.compile(r'^\s*[-*•]\s+')

RE_STREET = re.compile(r'\b(rue|avenue|av\.|bd|boulevard|chemin|route|impasse|all[ée]e|place|quai|ZA|ZI|BP|cedex)\b', re.I)
RE_PHONE  = re.compile(r'\+?\d[\d\.\s\-]{6,}\d')
RE_EMAIL  = re.compile(r'[\w\.-]+@[\w\.-]+\.\w+')
RE_URL    = re.compile(r'(https?://\S+|www\.\S+)')

def strip_markdown(s: Optional[str]) -> str:
    if not s:
        return ""
    out_lines = []
    for line in s.splitlines():
        line = _md_link.sub(lambda m: m.group(1) if m.groups() else "", line)
        line = _md_head.sub("", line)
        line = _md_bullet.sub("", line)
        line = _md_code.sub("", line)
        line = _md_emph.sub("", line)
        out_lines.append(line)
    out = "\n".join(out_lines)
    out = re.sub(r'\s+', ' ', out).strip()
    return out

def looks_like_person_name(s: Optional[str]) -> bool:
    if not s:
        return False
    s = strip_markdown(s)
    tokens = [t for t in re.split(r"[\s\-]+", s) if t]
    if len(tokens) < 2:
        return False
    return sum(1 for t in tokens if re.match(r"^[A-ZÀ-ÖØ-Ý][a-zà-öø-ÿ’'\-]+$", t)) >= 2

def sanitize_lead_strings(lead: Dict) -> Dict:
    for k in ["full_name", "first_name", "last_name", "company", "job_title", "email", "phone", "address"]:
        if k in lead and isinstance(lead[k], str):
            lead[k] = strip_markdown(lead[k])
    return lead

# ===================
# LLM – extraction/structuration + retriage
# ===================
def _chat_complete_text(prompt: str, temperature: float = 0.3) -> str:
    res = mistral.chat.complete(
        model=MISTRAL_CHAT_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=temperature,
    )
    try:
        return res.output[0].content[0].text.strip()
    except Exception:
        pass
    try:
        return res.choices[0].message.content.strip()
    except Exception:
        return ""

def naive_extract(text: str) -> Dict:
    clean = strip_markdown(text)
    email = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', clean)
    phone = re.search(r'(\+?\d[\d\s\.\-]{7,}\d)', clean)

    lines = [l.strip() for l in clean.splitlines() if l.strip()]
    full_name = next((l for l in lines[:6] if looks_like_person_name(l)), None)
    job_title = next(
        (l[:80] for l in lines[:10] if re.search(
            r'(CEO|CTO|COO|CMO|Sales|Commercial|Marketing|Achat|Achats|RH|DRH|DG|Direction|Manager|Responsable|Chef de|Ingénieur|Consultant|Founder|Président|Gérant|Directeur)',
            l, re.I)),
        None
    )
    company = next(
        (l[:80] for l in lines[:10]
         if l not in {full_name, job_title} and not re.search(r'@|https?://|www\.|\+?\d', l)),
        None
    )
    return {
        "full_name": full_name,
        "company": company,
        "job_title": job_title,
        "email": email.group(0) if email else None,
        "phone": (phone.group(0).replace(" ", "") if phone else None),
        "address": None
    }

def llm_structurize(rough: Dict, raw_ocr: Optional[str] = None) -> Dict:
    prompt = f"""
Tu reçois 1) le texte OCR brut (peut contenir du Markdown) et 2) un dict rough possiblement erroné.
Tâche: déduis les champs depuis l'OCR (prioritaire), corrige rough si besoin.
RENVOIE STRICTEMENT un JSON avec clés:
full_name, first_name, last_name, company, job_title, email, phone (format E.164 si possible), address.
Règles:
- Ignore la mise en forme Markdown (#, **, _, liens).
- N'invente rien: null si inconnu.
- Si la première ligne est la société et non la personne, ne confonds pas.
OCR: {json.dumps(raw_ocr or "", ensure_ascii=False)[:6000]}
Rough: {json.dumps(rough, ensure_ascii=False)}
Réponse uniquement le JSON.
"""
    content = _chat_complete_text(prompt, temperature=0.2)
    try:
        parsed = json.loads(content)
    except Exception:
        parsed = dict(rough)

    for k in ["full_name", "first_name", "last_name", "company", "job_title", "email", "phone", "address"]:
        parsed.setdefault(k, None)

    if not (parsed.get("first_name") and parsed.get("last_name")) and parsed.get("full_name"):
        glast, gfirst = _guess_last_first(parsed["full_name"])
        parsed["last_name"] = parsed.get("last_name") or glast
        parsed["first_name"] = parsed.get("first_name") or gfirst

    parsed = sanitize_lead_strings(parsed)
    if parsed.get("phone"):
        parsed["phone"] = re.sub(r"[^\d+]", "", parsed["phone"])

    parsed = retriage_lead(parsed)
    return parsed

def retriage_lead(lead: Dict) -> Dict:
    comp = lead.get("company") or ""
    fname = lead.get("full_name") or ""
    if looks_like_person_name(comp) and not looks_like_person_name(fname):
        lead["full_name"], lead["company"] = comp, fname
        glast, gfirst = _guess_last_first(lead["full_name"])
        if glast: lead["last_name"] = glast
        if gfirst: lead["first_name"] = gfirst
    if not lead.get("full_name") and (lead.get("first_name") or lead.get("last_name")):
        parts = [lead.get("first_name") or "", lead.get("last_name") or ""]
        lead["full_name"] = " ".join(p for p in parts if p).strip() or None
    return lead

# ---- Helpers nom complet → "NOM, Prénom"
def _guess_last_first(full_name: str):
    s = re.sub(r"\s+", " ", (full_name or "")).strip()
    if not s:
        return None, None
    if "," in s:
        left, right = [p.strip() for p in s.split(",", 1)]
        return left, right
    parts = s.split(" ")
    if len(parts) >= 2:
        uppers = [p for p in parts if p.isupper() and len(p) > 1]
        if uppers:
            last = " ".join(uppers)
            first = " ".join([p for p in parts if p not in uppers]) or None
            return last, first
        return parts[-1], " ".join(parts[:-1])
    return None, s

# ---- Nettoyages avancés nom/société pour le TITRE
def normalize_company_name(s: Optional[str], email: Optional[str] = None) -> str:
    s = strip_markdown(s or "")
    s = RE_URL.sub("", s)
    s = RE_EMAIL.sub("", s)
    s = RE_PHONE.sub("", s)
    for sep in [" - ", " — ", " – "]:
        if sep in s:
            left, right = s.split(sep, 1)
            if RE_STREET.search(right) or re.search(r'\d', right):
                s = left
                break
    m = RE_STREET.search(s)
    if m:
        s = s[:m.start()]
    words = [w for w in re.split(r"\s+", s) if w and not re.match(r"^\d", w)]
    s = " ".join(words[:5]).strip(" ,;-")
    if not s and email:
        dom = email.split("@")[-1]
        root = dom.split(".")[0]
        s = root.replace("-", " ").upper()
    return s[:80]

def strip_company_prefix_from_full_name(full_name: Optional[str], company: Optional[str], email: Optional[str] = None) -> str:
    s = strip_markdown(full_name or "")
    comp = normalize_company_name(company or "", email=email)
    if comp and s.upper().startswith(comp.upper() + " "):
        s = s[len(comp):].strip()
    s = RE_EMAIL.sub("", s)
    s = RE_PHONE.sub("", s)
    s = RE_URL.sub("", s)
    s = re.sub(r"\s+", " ", s).strip(" -–—,")
    return s

def sanitize_component_for_title(s: Optional[str]) -> str:
    s = strip_markdown(s or "")
    s = RE_EMAIL.sub("", s)
    s = RE_PHONE.sub("", s)
    s = RE_URL.sub("", s)
    s = re.sub(r"\s+", " ", s).strip(" -–—,")
    return s

def postprocess_lead(lead: Dict, raw_ocr: str) -> Dict:
    lead["company"] = normalize_company_name(lead.get("company"), lead.get("email"))
    lead["full_name"] = strip_company_prefix_from_full_name(lead.get("full_name"), lead.get("company"), lead.get("email"))
    if lead.get("full_name") and (not lead.get("first_name") or not lead.get("last_name")):
        glast, gfirst = _guess_last_first(lead["full_name"])
        lead["last_name"]  = lead.get("last_name")  or glast
        lead["first_name"] = lead.get("first_name") or gfirst
    return lead

def format_lead_title(lead: Dict) -> str:
    last = (lead.get("last_name") or "").strip()
    first = (lead.get("first_name") or "").strip()
    company = normalize_company_name(lead.get("company"), lead.get("email"))
    if not (last and first) and lead.get("full_name"):
        glast, gfirst = _guess_last_first(lead["full_name"])
        last  = last or (glast or "")
        first = first or (gfirst or "")
    name_part = sanitize_component_for_title(f"{last.upper()}, {first}" if (last and first) else (lead.get("full_name") or ""))
    company_clean = sanitize_component_for_title(company)
    title = " - ".join([p for p in [name_part, company_clean] if p]) or "Lead (inconnu)"
    return title[:120]

# ---- Title prop detection & cleaning
def get_title_prop_key(db_meta: Dict) -> str:
    for k, v in db_meta.get("properties", {}).items():
        if v.get("type") == "title":
            return k
    return "Name"

def clean_title_text(s: str) -> str:
    s = strip_markdown(s or "")
    s = re.sub(r"\s+", " ", s).strip()
    s = re.sub(r"^[-–—]+|[-–—]+$", "", s).strip()
    s = re.sub(r"\s*[-–—]\s*", " - ", s)
    return s if s else "Lead (inconnu)"

# ===================
# EMAIL – contexte compressé
# ===================
def compress_context_for_email(web_context: Optional[str]) -> str:
    if not web_context:
        return ""
    prompt = f"""
Synthétise pour un email B2B en 5 puces factuelles et courtes :
- Secteur/activité
- Taille (ordre de grandeur)
- Produits/services clés
- Localisation(s)
- Actu/points saillants récents
Texte source :
{web_context[:5000]}
Réponds UNIQUEMENT avec 5 puces, sans phrase d'intro.
"""
    return _chat_complete_text(prompt, temperature=0.2).strip()

def prepare_email_context_block(lead: Dict, web_context: Optional[str]) -> str:
    bullets = compress_context_for_email(web_context)
    parts = []
    if lead.get("company"):
        parts.append(f"Entreprise : {lead['company']}")
    if lead.get("job_title") and lead.get("full_name"):
        parts.append(f"Contact : {lead['full_name']} — {lead['job_title']}")
    if bullets:
        parts.append("Contexte :\n" + bullets)
    return "\n".join(parts)

def generate_email_draft(lead: Dict, notes: str, web_context: Optional[str] = None) -> str:
    ctx = prepare_email_context_block(lead, web_context)
    prompt = f"""
Tu es SDR chez Nin-IA. Personnalise un email court (100-120 mots).
Objectif : proposer un échange 15 min (Teams/téléphone) cette semaine.
Contraintes :
- Utilise AU MOINS 2 infos concrètes du bloc “Contexte” ci-dessous.
- Adapte le ton aux notes. Pas de fluff.
- B2B uniquement.

Lead: {json.dumps(lead, ensure_ascii=False)}
Notes: {notes or "—"}
Contexte consolidé:
{ctx}

Structure attendue :
1) Accroche personnalisée (1 phrase)
2) Valeur pour eux (1-2 phrases) en citant 2 infos du contexte
3) Proposition d'échange (créneaux)
4) Signature courte Nin-IA

Réponds par le texte de l'email UNIQUEMENT.
"""
    return _chat_complete_text(prompt, temperature=0.5)

# ===================
# Agents (websearch)
# ===================
def _create_websearch_agent() -> Optional[str]:
    url = f"{MISTRAL_AGENTS_URL}/agents"
    payload = {
        "model": MISTRAL_AGENT_MODEL,
        "name": "Websearch Agent",
        "description": "Agent capable de chercher sur le web des infos récentes (personne, entreprise).",
        "instructions": "Utilise le connecteur web_search pour chercher des informations factuelles et références.",
        "tools": [{"type": "web_search"}],
        "completion_args": {"temperature": 0.2, "top_p": 0.95},
    }
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {MISTRAL_KEY}",
            "Content-Type": "application/json",
            "Accept": "application/json",
        },
        json=payload,
        timeout=30,
    )
    r.raise_for_status()
    data = r.json()
    return data.get("id") or data.get("agent_id")

def get_websearch_agent_id() -> Optional[str]:
    key = "mistral_websearch_agent_id"
    if key in st.session_state and st.session_state[key]:
        return st.session_state[key]
    try:
        agent_id = _create_websearch_agent()
        st.session_state[key] = agent_id
        return agent_id
    except Exception:
        return None

def _ask_websearch_agent(agent_id: str, query: str) -> Tuple[str, List[Dict]]:
    url = f"{MISTRAL_AGENTS_URL}/conversations"
    payload = {"agent_id": agent_id, "inputs": query, "stream": False}
    r = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {MISTRAL_KEY}",
            "Content-Type": "application/json",
            "Accept": "application/json",
        },
        json=payload,
        timeout=60,
    )
    r.raise_for_status()
    data = r.json()
    outputs = data.get("outputs", [])
    text_parts: List[str] = []
    refs: List[Dict] = []
    for entry in outputs:
        if entry.get("type") == "message.output":
            for chunk in entry.get("content", []) or []:
                if chunk.get("type") == "text" and chunk.get("text"):
                    text_parts.append(chunk["text"])
                elif chunk.get("type") == "tool_reference" and chunk.get("url"):
                    refs.append({
                        "title": chunk.get("title") or chunk.get("url"),
                        "url": chunk.get("url"),
                        "source": chunk.get("source"),
                    })
    return ("\n".join(text_parts).strip() or "", refs)

def build_websearch_queries(lead: Dict) -> List[str]:
    full_name = (lead.get("full_name") or "").strip()
    company = (lead.get("company") or "").strip()
    role = (lead.get("job_title") or "").strip()
    queries: List[str] = []
    if full_name and company:
        queries.append(f"Informations récentes et profil public de {full_name} ({role}) chez {company}.")
    elif full_name:
        queries.append(f"Profil public et informations professionnelles de {full_name} ({role}).")
    if company:
        queries.append(f"Résumé de {company} (activité, effectifs, actualités récentes, produits).")
        queries.append(f"Opportunités d'usage de l'IA pour {company} (marketing, ops, support, data).")
    return [q for q in queries if q]

def run_web_enrichment(lead: Dict, user_notes: str) -> Tuple[str, List[Dict]]:
    agent_id = get_websearch_agent_id()
    queries = build_websearch_queries(lead)
    if agent_id and queries:
        try:
            final_text: List[str] = []
            all_refs: List[Dict] = []
            for q in queries:
                text, refs = _ask_websearch_agent(agent_id, q)
                if text:
                    final_text.append(text)
                if refs:
                    all_refs.extend(refs)
            if final_text:
                final_text.append(
                    "\nSynthèse actionnable: propose des pistes concrètes où Nin-IA peut aider (formations, audits, modules)."
                )
                return ("\n\n".join(final_text), all_refs)
        except Exception:
            pass
    prompt = f"""
Tu vas générer un bref contexte exploitable sur ce lead puis des idées d'usage de l'IA.
Lead: {json.dumps(lead, ensure_ascii=False)}
Notes: {user_notes}
1) Contexte probable (hypothèses explicites si nécessaire).
2) 6 idées d'applications IA concrètes par domaine (marketing, ops, support, data, RH, produit), liste.
"""
    return (_chat_complete_text(prompt, temperature=0.4), [])

# ===================
# NOTION – utilitaires schéma
# ===================
def notion_get_db_meta() -> Dict:
    return notion.databases.retrieve(NOTION_DB)

def _normalize_name(name: str) -> str:
    if not name:
        return ""
    nf = unicodedata.normalize("NFD", name)
    without_accents = "".join(ch for ch in nf if unicodedata.category(ch) != "Mn")
    return re.sub(r"\s+", " ", without_accents).strip().lower()

def ensure_db_schema():
    meta = notion_get_db_meta()
    props = meta.get("properties", {})

    def ensure_rich_text(name: str):
        if name in props and props[name]["type"] == "rich_text":
            return
        notion.databases.update(database_id=NOTION_DB, properties={name: {"rich_text": {}}})

    def ensure_email(name: str):
        if name in props and props[name]["type"] == "email":
            return
        notion.databases.update(database_id=NOTION_DB, properties={name: {"email": {}}})

    def ensure_phone(name: str):
        if name in props and props[name]["type"] == "phone_number":
            return
        notion.databases.update(database_id=NOTION_DB, properties={name: {"phone_number": {}}})

    def ensure_multi_select(name: str, options: List[str]):
        nonlocal props
        if name not in props or props[name]["type"] != "multi_select":
            notion.databases.update(
                database_id=NOTION_DB,
                properties={name: {"multi_select": {"options": [{"name": o} for o in options]}}}
            )
        else:
            current = set(opt["name"] for opt in props[name]["multi_select"]["options"])
            missing = [o for o in options if o not in current]
            if missing:
                new_opts = props[name]["multi_select"]["options"] + [{"name": o} for o in missing]
                notion.databases.update(
                    database_id=NOTION_DB,
                    properties={name: {"multi_select": {"options": new_opts}}}
                )

    def ensure_status(name: str, required_value: str):
        if name not in props:
            notion.databases.update(
                database_id=NOTION_DB,
                properties={name: {"select": {"options": [{"name": required_value}]}}}
            )
            return
        p = props[name]
        if p["type"] == "status":
            cur = set(opt["name"] for opt in p["status"]["options"])
            if required_value not in cur:
                new_opts = p["status"]["options"] + [{"name": required_value}]
                notion.databases.update(
                    database_id=NOTION_DB,
                    properties={name: {"status": {"options": new_opts}}}
                )
        elif p["type"] == "select":
            cur = set(opt["name"] for opt in p["select"]["options"])
            if required_value not in cur:
                new_opts = p["select"]["options"] + [{"name": required_value}]
                notion.databases.update(
                    database_id=NOTION_DB,
                    properties={name: {"select": {"options": new_opts}}}
                )
        else:
            notion.databases.update(
                database_id=NOTION_DB,
                properties={name: {"select": {"options": [{"name": required_value}]}}}
            )

    ensure_status(PROP_STATUS, TARGET_STATUS_VALUE)
    ensure_email(PROP_EMAIL)
    ensure_phone(PROP_PHONE)
    ensure_rich_text(PROP_COMPANY)
    ensure_rich_text(PROP_NOTES)
    ensure_rich_text(PROP_EMAIL_DRAFT)
    ensure_multi_select(PROP_TOPIC, TOPIC_OPTIONS)

try:
    ensure_db_schema()
except Exception as e:
    st.warning(f"Impossible de garantir le schéma Notion (droits/partage ?) : {e}")

# ===================
# NOTION – CRUD
# ===================
def notion_find_page_by_email(email: Optional[str]) -> Optional[str]:
    if not email:
        return None
    try:
        res = notion.databases.query(
            **{
                "database_id": NOTION_DB,
                "filter": {"property": PROP_EMAIL, "email": {"equals": email}}
            }
        )
        results = res.get("results", [])
        return results[0]["id"] if results else None
    except Exception:
        return None

def build_properties_for_upsert(lead: Dict, topics: List[str], notes: str, db_meta: Dict) -> Dict:
    props: Dict = {}

    # Title fiable : on écrit sur la vraie propriété "title"
    title_key = get_title_prop_key(db_meta)
    title_text = clean_title_text(format_lead_title(lead))
    if DEBUG:
        st.caption(f"title_key={title_key} → {title_text}")
    props[title_key] = {"title": [{"type": "text", "text": {"content": title_text}}]}

    # Statut
    if "properties" in db_meta and PROP_STATUS in db_meta["properties"]:
        ptype = db_meta["properties"][PROP_STATUS]["type"]
        if ptype == "status":
            props[PROP_STATUS] = {"status": {"name": TARGET_STATUS_VALUE}}
        elif ptype == "select":
            props[PROP_STATUS] = {"select": {"name": TARGET_STATUS_VALUE}}

    # Entreprise
    if lead.get("company") and PROP_COMPANY in db_meta["properties"] and db_meta["properties"][PROP_COMPANY]["type"] == "rich_text":
        props[PROP_COMPANY] = {"rich_text": [{"text": {"content": strip_markdown(lead["company"])}}]}

    # E-mail
    if lead.get("email") and PROP_EMAIL in db_meta["properties"] and db_meta["properties"][PROP_EMAIL]["type"] == "email":
        props[PROP_EMAIL] = {"email": lead["email"]}

    # Téléphone
    if lead.get("phone") and PROP_PHONE in db_meta["properties"] and db_meta["properties"][PROP_PHONE]["type"] == "phone_number":
        props[PROP_PHONE] = {"phone_number": lead["phone"]}

    # Sujet (multi-select)
    if PROP_TOPIC in db_meta["properties"] and db_meta["properties"][PROP_TOPIC]["type"] == "multi_select":
        valid = set(opt["name"] for opt in db_meta["properties"][PROP_TOPIC]["multi_select"]["options"])
        selected = [{"name": t} for t in topics if t in valid]
        props[PROP_TOPIC] = {"multi_select": selected}

    # Notes
    if notes and PROP_NOTES in db_meta["properties"] and db_meta["properties"][PROP_NOTES]["type"] == "rich_text":
        props[PROP_NOTES] = {"rich_text": [{"text": {"content": notes}}]}

    return props

def notion_upsert_lead(lead: Dict, topics: List[str], notes: str) -> str:
    db_meta = notion_get_db_meta()
    props = build_properties_for_upsert(lead, topics, notes, db_meta)

    existing_id = notion_find_page_by_email(lead.get("email"))
    if existing_id:
        notion.pages.update(page_id=existing_id, properties=props)
        return existing_id

    page = notion.pages.create(parent={"database_id": NOTION_DB}, properties=props)

    # Ceinture+bretelles : reforce le title juste après création
    try:
        title_key = get_title_prop_key(notion_get_db_meta())
        title_text = clean_title_text(format_lead_title(lead))
        notion.pages.update(page_id=page["id"], properties={
            title_key: {"title": [{"type": "text", "text": {"content": title_text}}]}
        })
    except Exception:
        pass

    return page["id"]

def _to_rich_text_chunks(text: str, chunk_size: int = 1800) -> List[Dict]:
    chunks: List[Dict] = []
    if not text:
        return [{"text": {"content": ""}}]
    for i in range(0, len(text), chunk_size):
        segment = text[i : i + chunk_size]
        chunks.append({"text": {"content": segment}})
    return chunks

def notion_set_email_draft(page_id: str, draft: str) -> Tuple[bool, Optional[str]]:
    try:
        notion.pages.update(
            page_id=page_id,
            properties={PROP_EMAIL_DRAFT: {"rich_text": _to_rich_text_chunks(draft)}},
        )
        return True, None
    except Exception as e:
        return False, str(e)

def notion_append_email_draft_block(page_id: str, draft: str) -> Tuple[bool, Optional[str]]:
    try:
        heading_block = {
            "object": "block",
            "type": "heading_2",
            "heading_2": {"rich_text": [{"type": "text", "text": {"content": "Brouillon à envoyer"}}]},
        }
        code_block = {
            "object": "block",
            "type": "code",
            "code": {
                "language": "markdown",
                "rich_text": [{"type": "text", "text": {"content": chunk["text"]["content"]}} for chunk in _to_rich_text_chunks(draft)],
            },
        }
        notion.blocks.children.append(block_id=page_id, children=[heading_block, code_block])
        return True, None
    except Exception as e:
        return False, str(e)

# ===================
# UI
# ===================
st.title("🪪 Carte → Notion (Mistral OCR + LLM)")
st.caption("Photo (mobile OK) → OCR → Lead Notion (Statut = Leads entrant) → Sujets → Notes → Brouillon email.")

photo = st.camera_input("Prends la carte en photo")
notes = st.text_area("Parlez-nous de vos besoins", "")

topics = st.multiselect(
    "De quoi désirez-vous discuter ?",
    TOPIC_OPTIONS,
    default=[],
    help="Sera écrit dans la propriété multi-sélection."
)

col1, col2 = st.columns(2)
with col1:
    uploaded = st.file_uploader("Ou téléverse une image", type=["png","jpg","jpeg"])
with col2:
    st.write("")

img = uploaded if uploaded is not None else photo

if st.button("Traiter") and img:
    img_bytes = img.getvalue()
    img_bytes = preprocess_for_ocr(img_bytes)

    # 1) OCR
    try:
        with st.spinner("OCR Mistral…"):
            ocr_text = call_mistral_ocr(img_bytes)
            if not ocr_text.strip():
                raise RuntimeError("OCR vide.")
    except Exception as e:
        st.error(f"OCR en échec : {e}")
        st.stop()

    # 2) Extraction → normalisation (LLM prioritaire + retriage)
    rough = naive_extract(ocr_text)
    with st.spinner("Structuration (LLM + retriage)…"):
        lead = llm_structurize(rough, raw_ocr=ocr_text)
        lead = postprocess_lead(lead, ocr_text)

    # 3) Websearch (optionnel)
    with st.spinner("Recherche web (Mistral)…"):
        web_summary, web_refs = run_web_enrichment(lead, notes)

    # 4) Notion (upsert + statut + sujets + notes)
    try:
        with st.spinner("Écriture dans Notion…"):
            page_id = notion_upsert_lead(lead, topics, notes)
    except Exception as e:
        st.error(f"Notion en échec : {e}")
        st.stop()

    # 5) Brouillon d’email (avec contexte compressé)
    with st.spinner("Rédaction du brouillon d’email…"):
        draft = generate_email_draft(lead, notes, web_context=web_summary or None)
        ok, err = notion_set_email_draft(page_id, draft)
        if not ok:
            st.warning(f"Propriété '{PROP_EMAIL_DRAFT}' indisponible ({err}). Ajout dans le corps de la page…")
            ok2, err2 = notion_append_email_draft_block(page_id, draft)
            if ok2:
                st.info("Brouillon ajouté dans le corps de la page (bloc).")
            else:
                st.error(f"Impossible d'ajouter le brouillon : {err2}")

    st.success("✅ Lead créé/mis à jour (titre propre) + sujets + notes + brouillon.")
    st.subheader("Brouillon")
    st.code(draft, language="markdown")

    with st.expander("Texte OCR"):
        st.text(ocr_text)

    st.subheader("Contexte trouvé en ligne (Mistral Websearch)")
    if web_summary:
        st.markdown(web_summary)
    else:
        st.caption("Aucun résumé disponible.")
    if web_refs:
        st.caption("Sources")
        for ref in web_refs[:8]:
            title = ref.get("title") or ref.get("url")
            url = ref.get("url")
            src = ref.get("source")
            st.markdown(f"- [{title}]({url}){f' — {src}' if src else ''}")
else:
    st.caption("Autorise la caméra sur mobile, ou dépose un fichier.")
